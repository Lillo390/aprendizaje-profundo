{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"GU6Ab3QckvLF"},"source":["# **Ejemplo de uso del framework Stable Baselines 3 en Space Invaders**"]},{"cell_type":"markdown","metadata":{"id":"c50j4558k-7R"},"source":["Primero instalamos el framework"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BLumqs3_F-o7","executionInfo":{"status":"ok","timestamp":1681577894195,"user_tz":-120,"elapsed":13215,"user":{"displayName":"Carlos Blom-Dahl","userId":"13821063228198029433"}},"outputId":"cc8a8c33-86f2-4032-c50f-fc10b7ce8b2a"},"source":["# Esto hacía falta antes\n","#!pip install --upgrade --force-reinstall gym\n","\n","# La opcion oficial no funciona 5/4/2023\n","#!pip install stable_baselines3[extra]\n","\n","# Alternativa \n","!pip install git+https://github.com/carlosluis/stable-baselines3@fix_tests"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/carlosluis/stable-baselines3@fix_tests\n","  Cloning https://github.com/carlosluis/stable-baselines3 (to revision fix_tests) to /tmp/pip-req-build-8_y9ub8r\n","  Running command git clone --filter=blob:none --quiet https://github.com/carlosluis/stable-baselines3 /tmp/pip-req-build-8_y9ub8r\n","  Running command git checkout -b fix_tests --track origin/fix_tests\n","  Switched to a new branch 'fix_tests'\n","  Branch 'fix_tests' set up to track remote branch 'fix_tests' from 'origin'.\n","  Resolved https://github.com/carlosluis/stable-baselines3 to commit 6617e6e73cb3a70f3e88cea780ea12bed95c099e\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: gym==0.26.2 in /usr/local/lib/python3.9/dist-packages (from stable-baselines3==2.0.0a0) (0.26.2)\n","Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.9/dist-packages (from stable-baselines3==2.0.0a0) (2.0.0+cu118)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.9/dist-packages (from stable-baselines3==2.0.0a0) (2.2.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from stable-baselines3==2.0.0a0) (1.5.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from stable-baselines3==2.0.0a0) (3.7.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from stable-baselines3==2.0.0a0) (1.22.4)\n","Requirement already satisfied: importlib-metadata~=4.13 in /usr/local/lib/python3.9/dist-packages (from stable-baselines3==2.0.0a0) (4.13.0)\n","Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.9/dist-packages (from gym==0.26.2->stable-baselines3==2.0.0a0) (0.0.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata~=4.13->stable-baselines3==2.0.0a0) (3.15.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a0) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a0) (3.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a0) (3.11.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a0) (4.5.0)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a0) (2.0.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a0) (3.1.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.11->stable-baselines3==2.0.0a0) (16.0.1)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.11->stable-baselines3==2.0.0a0) (3.25.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->stable-baselines3==2.0.0a0) (1.0.7)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->stable-baselines3==2.0.0a0) (2.8.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->stable-baselines3==2.0.0a0) (1.4.4)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->stable-baselines3==2.0.0a0) (4.39.3)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->stable-baselines3==2.0.0a0) (3.0.9)\n","Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->stable-baselines3==2.0.0a0) (5.12.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->stable-baselines3==2.0.0a0) (23.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->stable-baselines3==2.0.0a0) (0.11.0)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->stable-baselines3==2.0.0a0) (8.4.0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->stable-baselines3==2.0.0a0) (2022.7.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3==2.0.0a0) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.11->stable-baselines3==2.0.0a0) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.11->stable-baselines3==2.0.0a0) (1.3.0)\n"]}]},{"cell_type":"markdown","metadata":{"id":"uw5T73jzlDEV"},"source":["descargamos los roms de atari"]},{"cell_type":"code","source":["!pip3 install gym[atari,accept-rom-license]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aWOjFYFKG_pj","executionInfo":{"status":"ok","timestamp":1681577903682,"user_tz":-120,"elapsed":9498,"user":{"displayName":"Carlos Blom-Dahl","userId":"13821063228198029433"}},"outputId":"58840cd8-fab9-4972-f459-f73da38efcd6"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gym[accept-rom-license,atari] in /usr/local/lib/python3.9/dist-packages (0.26.2)\n","Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.9/dist-packages (from gym[accept-rom-license,atari]) (0.0.8)\n","Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.9/dist-packages (from gym[accept-rom-license,atari]) (1.22.4)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from gym[accept-rom-license,atari]) (2.2.1)\n","Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.9/dist-packages (from gym[accept-rom-license,atari]) (4.13.0)\n","Requirement already satisfied: ale-py~=0.8.0 in /usr/local/lib/python3.9/dist-packages (from gym[accept-rom-license,atari]) (0.8.1)\n","Requirement already satisfied: autorom[accept-rom-license]~=0.4.2 in /usr/local/lib/python3.9/dist-packages (from gym[accept-rom-license,atari]) (0.4.2)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.9/dist-packages (from ale-py~=0.8.0->gym[accept-rom-license,atari]) (5.12.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from ale-py~=0.8.0->gym[accept-rom-license,atari]) (4.5.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (4.65.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (8.1.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.27.1)\n","Requirement already satisfied: AutoROM.accept-rom-license in /usr/local/lib/python3.9/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (0.6.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.8.0->gym[accept-rom-license,atari]) (3.15.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (1.26.15)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.0.12)\n"]}]},{"cell_type":"markdown","metadata":{"id":"gfhXieo9lJhv"},"source":["Importamos las librerias necesarias."]},{"cell_type":"code","metadata":{"id":"D117b4vnF2DD","executionInfo":{"status":"ok","timestamp":1681577909115,"user_tz":-120,"elapsed":827,"user":{"displayName":"Carlos Blom-Dahl","userId":"13821063228198029433"}}},"source":["import gym\n","#from gym.wrappers import Monitor"],"execution_count":4,"outputs":[]},{"cell_type":"code","source":["import base64\n","from pathlib import Path\n","from IPython import display as ipythondisplay\n","from stable_baselines3 import A2C\n","from stable_baselines3.common.env_util import make_vec_env\n","import os\n","\n","from stable_baselines3.common.evaluation import evaluate_policy"],"metadata":{"id":"vhEKOT7WoEkd","executionInfo":{"status":"ok","timestamp":1681577921296,"user_tz":-120,"elapsed":11013,"user":{"displayName":"Carlos Blom-Dahl","userId":"13821063228198029433"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yxdRrV_klMcT"},"source":["Cargamos el entorno"]},{"cell_type":"code","metadata":{"id":"Ob4NFuqGGm3q"},"source":["ENV_NAME = 'SpaceInvaders-v4'\n","env = gym.make(ENV_NAME)\n","height, width, channels = env.observation_space.shape\n","actions = env.action_space.n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8ouKE00JlRCn"},"source":["Preparamos el entorno para poder descargar los videos"]},{"cell_type":"code","metadata":{"id":"LlUA_pIIhNWj"},"source":["# experiment_dir = os.path.abspath(\"./experiments/{}\".format(env.spec.id))\n","# monitor_path = os.path.join(experiment_dir, \"monitor\")\n","\n","# if not os.path.exists(monitor_path):\n","#     os.makedirs(monitor_path)\n","# env = Monitor(env, directory=monitor_path, video_callable=lambda count: count % record_video_every == 0, resume=True)\n","# record_video_every =1\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"64eWZy8-lbud"},"source":["Cargamos el modelo precargado, le damos a entrenar y luego salvamos el entorno.\n","\n","Vamos a dejar todos los parametros por defecto, que en el caso del Advantage Actor Critic (A2C) usa:\n","- learning_rate = 0,0007 , \n","- n_steps = 5 , \n","- gamma = 0,99 ,\n","- gae_lambda = 1,0 , \n","- ent_coef = 0,0 , \n","- vf_coef = 0,5 , \n","- max_grad_norm = 0,5 , \n","- rms_prop_eps = 1e-05"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1-vNtcuDGzAa","executionInfo":{"status":"ok","timestamp":1681565752149,"user_tz":-120,"elapsed":129119,"user":{"displayName":"Carlos Blom-Dahl","userId":"13821063228198029433"}},"outputId":"1f6daecb-d5a0-4536-d67c-9ac0cff36e62"},"source":["model = A2C(\"MlpPolicy\", env, verbose=1) #Podemos elegir entre varias politicas, como MLPpolicy, CnnPolicy, MultiInputPolicy\n","model.learn(total_timesteps=5000)\n","model.save(\"a2c_SpaceInvaders\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using cpu device\n","Wrapping the env with a `Monitor` wrapper\n","Wrapping the env in a DummyVecEnv.\n","Wrapping the env in a VecTransposeImage.\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 36        |\n","|    iterations         | 100       |\n","|    time_elapsed       | 13        |\n","|    total_timesteps    | 500       |\n","| train/                |           |\n","|    entropy_loss       | -1.51     |\n","|    explained_variance | 0.0363    |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 99        |\n","|    policy_loss        | -6.86e-05 |\n","|    value_loss         | 1.52e-09  |\n","-------------------------------------\n","-------------------------------------\n","| rollout/              |           |\n","|    ep_len_mean        | 514       |\n","|    ep_rew_mean        | 50        |\n","| time/                 |           |\n","|    fps                | 35        |\n","|    iterations         | 200       |\n","|    time_elapsed       | 27        |\n","|    total_timesteps    | 1000      |\n","| train/                |           |\n","|    entropy_loss       | -1.45     |\n","|    explained_variance | -0.0299   |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 199       |\n","|    policy_loss        | -7.96e-06 |\n","|    value_loss         | 6.56e-11  |\n","-------------------------------------\n","-------------------------------------\n","| rollout/              |           |\n","|    ep_len_mean        | 506       |\n","|    ep_rew_mean        | 45        |\n","| time/                 |           |\n","|    fps                | 36        |\n","|    iterations         | 300       |\n","|    time_elapsed       | 41        |\n","|    total_timesteps    | 1500      |\n","| train/                |           |\n","|    entropy_loss       | -1.11     |\n","|    explained_variance | -0.00251  |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 299       |\n","|    policy_loss        | -0.000372 |\n","|    value_loss         | 3.6e-07   |\n","-------------------------------------\n","-------------------------------------\n","| rollout/              |           |\n","|    ep_len_mean        | 506       |\n","|    ep_rew_mean        | 45        |\n","| time/                 |           |\n","|    fps                | 36        |\n","|    iterations         | 400       |\n","|    time_elapsed       | 54        |\n","|    total_timesteps    | 2000      |\n","| train/                |           |\n","|    entropy_loss       | -1.19     |\n","|    explained_variance | -0.000944 |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 399       |\n","|    policy_loss        | -0.00679  |\n","|    value_loss         | 1.41e-05  |\n","-------------------------------------\n","------------------------------------\n","| rollout/              |          |\n","|    ep_len_mean        | 773      |\n","|    ep_rew_mean        | 140      |\n","| time/                 |          |\n","|    fps                | 37       |\n","|    iterations         | 500      |\n","|    time_elapsed       | 67       |\n","|    total_timesteps    | 2500     |\n","| train/                |          |\n","|    entropy_loss       | -0.665   |\n","|    explained_variance | 4.59e-05 |\n","|    learning_rate      | 0.0007   |\n","|    n_updates          | 499      |\n","|    policy_loss        | -0.00918 |\n","|    value_loss         | 7.66e-05 |\n","------------------------------------\n","-------------------------------------\n","| rollout/              |           |\n","|    ep_len_mean        | 773       |\n","|    ep_rew_mean        | 140       |\n","| time/                 |           |\n","|    fps                | 37        |\n","|    iterations         | 600       |\n","|    time_elapsed       | 80        |\n","|    total_timesteps    | 3000      |\n","| train/                |           |\n","|    entropy_loss       | -0.524    |\n","|    explained_variance | 0.00319   |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 599       |\n","|    policy_loss        | -0.000213 |\n","|    value_loss         | 3.8e-06   |\n","-------------------------------------\n","-------------------------------------\n","| rollout/              |           |\n","|    ep_len_mean        | 756       |\n","|    ep_rew_mean        | 118       |\n","| time/                 |           |\n","|    fps                | 38        |\n","|    iterations         | 700       |\n","|    time_elapsed       | 92        |\n","|    total_timesteps    | 3500      |\n","| train/                |           |\n","|    entropy_loss       | -0.647    |\n","|    explained_variance | 0.407     |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 699       |\n","|    policy_loss        | -1.88e-06 |\n","|    value_loss         | 4.82e-12  |\n","-------------------------------------\n","-------------------------------------\n","| rollout/              |           |\n","|    ep_len_mean        | 725       |\n","|    ep_rew_mean        | 95        |\n","| time/                 |           |\n","|    fps                | 38        |\n","|    iterations         | 800       |\n","|    time_elapsed       | 104       |\n","|    total_timesteps    | 4000      |\n","| train/                |           |\n","|    entropy_loss       | -0.607    |\n","|    explained_variance | -1.57e-05 |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 799       |\n","|    policy_loss        | -0.00439  |\n","|    value_loss         | 5.78e-05  |\n","-------------------------------------\n","-------------------------------------\n","| rollout/              |           |\n","|    ep_len_mean        | 720       |\n","|    ep_rew_mean        | 109       |\n","| time/                 |           |\n","|    fps                | 38        |\n","|    iterations         | 900       |\n","|    time_elapsed       | 116       |\n","|    total_timesteps    | 4500      |\n","| train/                |           |\n","|    entropy_loss       | -0.345    |\n","|    explained_variance | 0.000179  |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 899       |\n","|    policy_loss        | -0.000671 |\n","|    value_loss         | 9.82e-05  |\n","-------------------------------------\n","------------------------------------\n","| rollout/              |          |\n","|    ep_len_mean        | 706      |\n","|    ep_rew_mean        | 98.6     |\n","| time/                 |          |\n","|    fps                | 38       |\n","|    iterations         | 1000     |\n","|    time_elapsed       | 128      |\n","|    total_timesteps    | 5000     |\n","| train/                |          |\n","|    entropy_loss       | -0.33    |\n","|    explained_variance | 7.68e-05 |\n","|    learning_rate      | 0.0007   |\n","|    n_updates          | 999      |\n","|    policy_loss        | 1.63e-05 |\n","|    value_loss         | 6.56e-08 |\n","------------------------------------\n"]}]},{"cell_type":"code","metadata":{"id":"AeIgpBKZpPcf"},"source":["recompensa_media, desviacion = evaluate_policy(model, model.get_env(), deterministic=True, n_eval_episodes=20)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"recompensa_media:{recompensa_media:.2f} +/- {desviacion:.2f}\")"],"metadata":{"id":"tds9ubHuDN4C","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681566603112,"user_tz":-120,"elapsed":193,"user":{"displayName":"Carlos Blom-Dahl","userId":"13821063228198029433"}},"outputId":"1414fa72-ef0b-44f0-99bd-feca39966f70"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["recompensa_media:0.00 +/- 0.00\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"4ycp3xvPUd1U"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["--------------------\n","# Implementación de DQL\n"],"metadata":{"id":"ypnMbOL9ryVo"}},{"cell_type":"markdown","source":["Para implementar _Deep Q-Network_, necesitaremos emplear la biblioteca _TensorFlow_."],"metadata":{"id":"6Fs8pQ9btZAn"}},{"cell_type":"code","source":["!pip3 install tensorflow==2.10.1\n","!pip install keras-rl2\n","!pip install h5py\n","!pip install Pillow"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T4hv3LKgtNpa","executionInfo":{"status":"ok","timestamp":1681577843221,"user_tz":-120,"elapsed":27967,"user":{"displayName":"Carlos Blom-Dahl","userId":"13821063228198029433"}},"outputId":"18b011aa-fb9c-43b8-b53f-3b323e1ae0c3"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tensorflow==2.10.1 in /usr/local/lib/python3.9/dist-packages (2.10.1)\n","Requirement already satisfied: keras<2.11,>=2.10.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.1) (2.10.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.1) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.1) (3.8.0)\n","Requirement already satisfied: tensorboard<2.11,>=2.10 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.1) (2.10.1)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.1) (1.53.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.1) (1.1.2)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.1) (3.19.6)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.1) (1.22.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.1) (23.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.1) (2.2.0)\n","Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.1) (2.10.0)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.1) (0.4.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.1) (0.32.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.1) (1.14.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.1) (3.3.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.1) (1.4.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.1) (16.0.0)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.1) (23.3.3)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.1) (1.6.3)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.1) (4.5.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.1) (67.6.1)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.1) (1.16.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow==2.10.1) (0.40.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.1) (3.4.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.1) (2.27.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.1) (0.6.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.1) (2.17.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.1) (2.2.3)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.1) (1.8.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.1) (0.4.6)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (0.2.8)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (5.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (4.13.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (3.4)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (2022.12.7)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (2.1.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (3.15.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (3.2.2)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: keras-rl2 in /usr/local/lib/python3.9/dist-packages (1.0.5)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.9/dist-packages (from keras-rl2) (2.10.1)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (23.3.3)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (16.0.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (23.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (0.32.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (3.3.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (4.5.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (2.2.0)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (1.22.4)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (1.1.2)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (0.4.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (1.16.0)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (3.19.6)\n","Requirement already satisfied: tensorboard<2.11,>=2.10 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (2.10.1)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (1.53.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (1.6.3)\n","Requirement already satisfied: keras<2.11,>=2.10.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (2.10.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (67.6.1)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (3.8.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (0.2.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (1.4.0)\n","Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (2.10.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow->keras-rl2) (0.40.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (2.27.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (0.4.6)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (3.4.3)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (0.6.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (2.17.2)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (1.8.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (2.2.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (0.2.8)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (5.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (4.13.0)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (3.4)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (2.1.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (3.15.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (3.2.2)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: h5py in /usr/local/lib/python3.9/dist-packages (3.8.0)\n","Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.9/dist-packages (from h5py) (1.22.4)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.9/dist-packages (8.4.0)\n"]}]},{"cell_type":"code","source":["print(\"The size of frame is: \", env.observation_space.shape)\n","print(\"No. of Actions: \", env.action_space.n)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R0DygVZa30g7","executionInfo":{"status":"ok","timestamp":1681579670338,"user_tz":-120,"elapsed":243,"user":{"displayName":"Carlos Blom-Dahl","userId":"13821063228198029433"}},"outputId":"a15366ff-2f6d-4d47-aa08-35a8e5e9514f"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["The size of frame is:  (210, 160, 3)\n","No. of Actions:  6\n"]}]},{"cell_type":"markdown","source":["## Preprocesamiento de los datos\n","\n","El preprocesado es un paso importante, ya que buscamos reducir la complejidad de nuestros estados para reducir el tiempo de computación necesari durante el entrenamiento.\n","\n","Los pasos que vamos a seguir son:\n","\n","* Pasar cada uno de los frames a escala de grises (porque el color no añade información relevante).\n","\n","* Recortar la pantalla (en nuestro caso, eliminamos la parte de debajo del jugador porque no aporta información útil).\n","\n","* Normalizar los valores de los píxeles.\n","\n","* Redimensionar el frame procesado."],"metadata":{"id":"9R0oqdnL9vO4"}},{"cell_type":"code","source":["!pip install -U scikit-image"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"adKdQt4s_Lze","executionInfo":{"status":"ok","timestamp":1681580176384,"user_tz":-120,"elapsed":24336,"user":{"displayName":"Carlos Blom-Dahl","userId":"13821063228198029433"}},"outputId":"81d077b2-cbc6-4fbd-81a6-388d4a3e067b"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.9/dist-packages (0.19.3)\n","Collecting scikit-image\n","  Downloading scikit_image-0.20.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pillow>=9.0.1\n","  Downloading Pillow-9.5.0-cp39-cp39-manylinux_2_28_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.9/dist-packages (from scikit-image) (3.1)\n","Requirement already satisfied: numpy>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image) (1.22.4)\n","Collecting scipy<1.9.2,>=1.8\n","  Downloading scipy-1.9.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image) (2.25.1)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image) (1.4.1)\n","Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image) (0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from scikit-image) (23.0)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.9/dist-packages (from scikit-image) (2023.3.21)\n","Installing collected packages: scipy, pillow, scikit-image\n","  Attempting uninstall: scipy\n","    Found existing installation: scipy 1.10.1\n","    Uninstalling scipy-1.10.1:\n","      Successfully uninstalled scipy-1.10.1\n","  Attempting uninstall: pillow\n","    Found existing installation: Pillow 8.4.0\n","    Uninstalling Pillow-8.4.0:\n","      Successfully uninstalled Pillow-8.4.0\n","  Attempting uninstall: scikit-image\n","    Found existing installation: scikit-image 0.19.3\n","    Uninstalling scikit-image-0.19.3:\n","      Successfully uninstalled scikit-image-0.19.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","dopamine-rl 4.0.6 requires gym<=0.25.2, but you have gym 0.26.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed pillow-9.5.0 scikit-image-0.20.0 scipy-1.9.1\n"]}]},{"cell_type":"code","source":["from skimage import transform\n","from skimage import io\n","from skimage.color import rgb2gray\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","\n","from collections import deque\n","\n","import random\n","\n","import warnings # This ignore all the warning messages that are normally printed during the training because of skiimage\n","warnings.filterwarnings('ignore') "],"metadata":{"id":"ax_7WxOC-twj","executionInfo":{"status":"ok","timestamp":1681581080099,"user_tz":-120,"elapsed":213,"user":{"displayName":"Carlos Blom-Dahl","userId":"13821063228198029433"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","    preprocess_frame:\n","    Take a frame.\n","    Grayscale it\n","    Resize it.\n","        __________________\n","        |                 |\n","        |                 |\n","        |                 |\n","        |                 |\n","        |_________________|\n","        \n","        to\n","        _____________\n","        |            |\n","        |            |\n","        |            |\n","        |____________|\n","    Normalize it.\n","    \n","    return preprocessed_frame\n","    \n","    \"\"\"\n","def preprocess_frame(frame):\n","    # Greyscale frame \n","    gray = rgb2gray(frame)\n","    \n","    # Crop the screen (remove the part below the player)\n","    # [Up: Down, Left: right]\n","    cropped_frame = gray[8:-12,4:-12]\n","    \n","    # Normalize Pixel Values\n","    normalized_frame = cropped_frame/255.0\n","    \n","    # Resize\n","    preprocessed_frame = transform.resize(normalized_frame, [110,84])\n","    \n","    return preprocessed_frame # 110x84x1 frame"],"metadata":{"id":"Vwn6BUcM-iXB","executionInfo":{"status":"ok","timestamp":1681580305711,"user_tz":-120,"elapsed":216,"user":{"displayName":"Carlos Blom-Dahl","userId":"13821063228198029433"}}},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":["Vamos a apilar (_stack_) los frames.\n","Apilar los frames es realmente importante porque nos ayuda a darle sentido de movimiento a nuestra Red Neuronal.\n","\n","PERO, no apilamos cada frame, saltamos 4 frames en cada paso de tiempo. Esto significa que solo se considera cada cuatro frames. Luego, usamos este frame para formar el frame apilado.\n","\n","El método de salto de frames ya está implementado en la biblioteca.\n","\n","* Primero preprocesamos el frame.\n","\n","* Luego lo añadimos a la cola (deque) que automáticamente elimina el frame más antiguo.\n","\n","* Finalmente construimos el estado apilado.\n","\n","Así es como funciona el apilado:\n","\n","* Para el primer frame, alimentamos con 4 frames.\n","* En cada paso de tiempo, añadimos el nuevo frame a la cola y luego los apilamos para formar un nuevo frame apilado.\n","\n","Y así sucesivamente.\n","\n","**Si hemos terminado, creamos una nueva pila con 4 frames nuevos (porque estamos en un nuevo episodio).**"],"metadata":{"id":"jzgJ1t1eAORa"}},{"cell_type":"code","source":["stack_size = 4 # We stack 4 frames\n","\n","# Initialize deque with zero-images one array for each image\n","stacked_frames  =  deque([np.zeros((110,84), dtype=np.int) for i in range(stack_size)], maxlen=4)\n","\n","def stack_frames(stacked_frames, state, is_new_episode):\n","    # Preprocess frame\n","    frame = preprocess_frame(state)\n","    \n","    if is_new_episode:\n","        # Clear our stacked_frames\n","        stacked_frames = deque([np.zeros((110,84), dtype=np.int) for i in range(stack_size)], maxlen=4)\n","        \n","        # Because we're in a new episode, copy the same frame 4x\n","        stacked_frames.append(frame)\n","        stacked_frames.append(frame)\n","        stacked_frames.append(frame)\n","        stacked_frames.append(frame)\n","        \n","        # Stack the frames\n","        stacked_state = np.stack(stacked_frames, axis=2)\n","        \n","    else:\n","        # Append frame to deque, automatically removes the oldest frame\n","        stacked_frames.append(frame)\n","\n","        # Build the stacked state (first dimension specifies different frames)\n","        stacked_state = np.stack(stacked_frames, axis=2) \n","    \n","    return stacked_state, stacked_frames"],"metadata":{"id":"jFppDlirBUtU","executionInfo":{"status":"ok","timestamp":1681580767009,"user_tz":-120,"elapsed":222,"user":{"displayName":"Carlos Blom-Dahl","userId":"13821063228198029433"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["### MODEL HYPERPARAMETERS\n","state_size = [110, 84, 4]      # Our input is a stack of 4 frames hence 110x84x4 (Width, height, channels) \n","action_size = env.action_space.n # 8 possible actions\n","learning_rate =  0.00025      # Alpha (aka learning rate)\n","\n","### TRAINING HYPERPARAMETERS\n","total_episodes = 50            # Total episodes for training\n","max_steps = 50000              # Max possible steps in an episode\n","batch_size = 64                # Batch size\n","\n","# Exploration parameters for epsilon greedy strategy\n","explore_start = 1.0            # exploration probability at start\n","explore_stop = 0.01            # minimum exploration probability \n","decay_rate = 0.00001           # exponential decay rate for exploration prob\n","\n","# Q learning hyperparameters\n","gamma = 0.9                    # Discounting rate\n","\n","### MEMORY HYPERPARAMETERS\n","pretrain_length = batch_size   # Number of experiences stored in the Memory when initialized for the first time\n","memory_size = 1000000          # Number of experiences the Memory can keep\n","\n","### PREPROCESSING HYPERPARAMETERS\n","stack_size = 4                 # Number of frames stacked\n","\n","### MODIFY THIS TO FALSE IF YOU JUST WANT TO SEE THE TRAINED AGENT\n","training = False\n","\n","## TURN THIS TO TRUE IF YOU WANT TO RENDER THE ENVIRONMENT\n","episode_render = False"],"metadata":{"id":"FQ4FiBEPBuCI","executionInfo":{"status":"ok","timestamp":1681580813057,"user_tz":-120,"elapsed":250,"user":{"displayName":"Carlos Blom-Dahl","userId":"13821063228198029433"}}},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":["Ahora vamos a crear el modelo DQL:\n","- Tomamos una pila de 4 fotogramas como entrada.\n","- Pasa a través de 3 convnets.\n","- Luego se aplana.\n","- Finalmente pasa a través de 2 capas completamente conectadas (_dense_).\n","- Devuelve un valor Q para cada acción."],"metadata":{"id":"120-qcAxB9gG"}},{"cell_type":"code","source":["import tensorflow as tf\n","\n","class DQNetwork:\n","    def __init__(self, state_size, action_size, learning_rate, name='DQNetwork'):\n","        self.state_size = state_size\n","        self.action_size = action_size\n","        self.learning_rate = learning_rate\n","        \n","        with tf.name_scope(name):\n","            # We create the placeholders\n","            # *state_size means that we take each elements of state_size in tuple hence is like if we wrote\n","            # [None, 84, 84, 4]\n","            self.inputs_ = tf.placeholder(tf.float32, [None, *state_size], name=\"inputs\")\n","            self.actions_ = tf.placeholder(tf.float32, [None, self.action_size], name=\"actions_\")\n","            \n","            # Remember that target_Q is the R(s,a) + ymax Qhat(s', a')\n","            self.target_Q = tf.placeholder(tf.float32, [None], name=\"target\")\n","            \n","            \"\"\"\n","            First convnet:\n","            CNN\n","            ELU\n","            \"\"\"\n","            # Input is 110x84x4 \n","            self.conv1 = tf.keras.layers.Conv2D(filters=32,\n","                                  kernel_size=[8, 8],\n","                                  strides=[4, 4],\n","                                  padding=\"VALID\",\n","                                  kernel_initializer=tf.keras.initializers.GlorotUniform(),\n","                                  name=\"conv1\")(self.inputs_)\n","\n","            \n","            self.conv1_out = tf.nn.elu(self.conv1, name=\"conv1_out\")\n","            \n","            \"\"\"\n","            Second convnet:\n","            CNN\n","            ELU\n","            \"\"\"\n","            self.conv2 = tf.keras.layers.Conv2D(filters = 64,\n","                                 kernel_size = [4,4],\n","                                 strides = [2,2],\n","                                 padding = \"VALID\",\n","                                kernel_initializer=tf.keras.initializers.GlorotUniform(),\n","                                 name = \"conv2\")(self.conv1_out)\n","\n","            self.conv2_out = tf.nn.elu(self.conv2, name=\"conv2_out\")            \n","            \n","            \"\"\"\n","            Third convnet:\n","            CNN\n","            ELU\n","            \"\"\"\n","            self.conv3 = tf.keras.layers.Conv2D(filters = 64,\n","                                 kernel_size = [3,3],\n","                                 strides = [2,2],\n","                                 padding = \"VALID\",\n","                                kernel_initializer=tf.keras.initializers.GlorotUniform(),\n","                                 name = \"conv3\")(self.conv2_out)\n","\n","            self.conv3_out = tf.nn.elu(self.conv3, name=\"conv3_out\")\n","            \n","            self.flatten = tf.keras.layers.Flatten()(self.conv3_out)\n","            \n","            self.fc1 = tf.keras.layers.Dense(units = 512,\n","                                  activation = tf.nn.elu,\n","                                  kernel_initializer=tf.keras.initializers.GlorotUniform(),\n","                                  name=\"fc1\")(self.flatten)\n","            \n","            self.output = tf.keras.layers.Dense(units = self.action_size, \n","                                           activation=None,\n","                                           kernel_initializer=tf.keras.initializers.GlorotUniform())(self.fc1)\n","            \n","\n","  \n","            # Q is our predicted Q value.\n","            self.Q = tf.reduce_sum(tf.multiply(self.output, self.actions_))\n","            \n","            # The loss is the difference between our predicted Q_values and the Q_target\n","            # Sum(Qtarget - Q)^2\n","            self.loss = tf.reduce_mean(tf.square(self.target_Q - self.Q))\n","            \n","            self.optimizer = tf.keras.optimizers.Adam(self.learning_rate).minimize(self.loss)\n","\n"],"metadata":{"id":"bZru-0AQCUet","executionInfo":{"status":"ok","timestamp":1681582281489,"user_tz":-120,"elapsed":228,"user":{"displayName":"Carlos Blom-Dahl","userId":"13821063228198029433"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["# Instantiate the DQNetwork\n","DQNetwork = DQNetwork(state_size, action_size, learning_rate)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":305},"id":"3zyRFjE4CdV4","executionInfo":{"status":"error","timestamp":1681582284510,"user_tz":-120,"elapsed":267,"user":{"displayName":"Carlos Blom-Dahl","userId":"13821063228198029433"}},"outputId":"604a7e51-3029-46d9-8cdd-76076723e9a4"},"execution_count":48,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-48-8ed4bb5aa52a>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Instantiate the DQNetwork\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mDQNetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDQNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-47-d80b36bfdc82>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, state_size, action_size, learning_rate, name)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;31m# *state_size means that we take each elements of state_size in tuple hence is like if we wrote\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;31m# [None, 84, 84, 4]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"inputs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"actions_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'placeholder'"]}]},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, Flatten, Dense\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.activations import relu, linear\n","from rl.agents.dqn import DQNAgent\n","from rl.policy import BoltzmannQPolicy\n","from rl.memory import SequentialMemory\n","import gym\n","import numpy as np\n","\n","# Obtener el entorno y extraer el número de acciones\n","ENV_NAME = 'SpaceInvaders-v4'\n","env = gym.make(ENV_NAME)\n","np.random.seed(123)\n","env.seed(123)\n","nb_actions = env.action_space.n\n","\n","# Construir el modelo con capas convolucionales\n","model = Sequential()\n","model.add(Conv2D(16, (3, 3), activation=relu, input_shape= env.observation_space.shape))\n","model.add(Conv2D(32, (3, 3), activation=relu))\n","model.add(Flatten())\n","model.add(Dense(nb_actions, activation=linear))\n","print(model.summary())\n","\n","# Configurar y compilar el agente\n","memory = SequentialMemory(limit=5000, window_length=1)\n","policy = BoltzmannQPolicy()\n","dqn = DQNAgent(model=model, nb_actions=nb_actions, memory=memory, nb_steps_warmup=10,\n","               target_model_update=1e-2, policy=policy)\n","dqn.compile(Adam(lr=1e-3), metrics=['mae'])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t2TEQJCMr_Ey","executionInfo":{"status":"ok","timestamp":1681578334699,"user_tz":-120,"elapsed":1497,"user":{"displayName":"Carlos Blom-Dahl","userId":"13821063228198029433"}},"outputId":"9b46d424-ee98-47a5-8744-be7c674d4cd1"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_4 (Conv2D)           (None, 208, 158, 16)      448       \n","                                                                 \n"," conv2d_5 (Conv2D)           (None, 206, 156, 32)      4640      \n","                                                                 \n"," flatten_2 (Flatten)         (None, 1028352)           0         \n","                                                                 \n"," dense_2 (Dense)             (None, 6)                 6170118   \n","                                                                 \n","=================================================================\n","Total params: 6,175,206\n","Trainable params: 6,175,206\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"]}]},{"cell_type":"code","source":["print(env.observation_space.shape)\n","print(type(env))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Poj0Kz7fv7E3","executionInfo":{"status":"ok","timestamp":1681576892161,"user_tz":-120,"elapsed":3,"user":{"displayName":"Carlos Blom-Dahl","userId":"13821063228198029433"}},"outputId":"c80d2510-6977-4662-8567-babdd9064133"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["(210, 160, 3)\n","<class 'gym.wrappers.order_enforcing.OrderEnforcing'>\n"]}]},{"cell_type":"code","source":["# Modificar la entrada para tener 4 dimensiones\n","#obs = np.expand_dims(env.reset(), axis=0)\n","dqn.fit(env, nb_steps=5000, visualize=False, verbose=2, nb_max_episode_steps=10000)\n","\n","# After training is done, we save the final weights.\n","dqn.save_weights('dqn_{}_weights.h5f'.format(ENV_NAME), overwrite=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":398},"id":"JtAl-f5pxI-u","executionInfo":{"status":"error","timestamp":1681578341879,"user_tz":-120,"elapsed":298,"user":{"displayName":"Carlos Blom-Dahl","userId":"13821063228198029433"}},"outputId":"f677f43c-38a7-42f1-baaa-ac7560171601"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Training for 5000 steps ...\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-cb635b26ce70>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Modificar la entrada para tener 4 dimensiones\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#obs = np.expand_dims(env.reset(), axis=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_max_episode_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# After training is done, we save the final weights.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/rl/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, env, nb_steps, action_repetition, callbacks, verbose, visualize, nb_max_start_steps, start_step_policy, log_interval, nb_max_episode_steps)\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;31m# This is were all of the work happens. We first perceive and compute the action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0;31m# (forward step) and then use the reward to improve (backward step).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m                 \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/rl/agents/dqn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, observation)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;31m# Select an action.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_recent_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mq_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_q_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mq_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/rl/agents/dqn.py\u001b[0m in \u001b[0;36mcompute_q_values\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_q_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mq_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_batch_q_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mq_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_actions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mq_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/rl/agents/dqn.py\u001b[0m in \u001b[0;36mcompute_batch_q_values\u001b[0;34m(self, state_batch)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_batch_q_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_state_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mq_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mq_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mq_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mpredict_on_batch\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1302\u001b[0m             )\n\u001b[1;32m   1303\u001b[0m         \u001b[0;31m# Validate and standardize user data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         inputs, _, _ = self._standardize_user_data(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_tensors_from_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2649\u001b[0;31m         return self._standardize_tensors(\n\u001b[0m\u001b[1;32m   2650\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2651\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py\u001b[0m in \u001b[0;36m_standardize_tensors\u001b[0;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001b[0m\n\u001b[1;32m   2688\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2689\u001b[0m             \u001b[0;31m# TODO(fchollet): run static checks with dataset output shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2690\u001b[0;31m             x = training_utils_v1.standardize_input_data(\n\u001b[0m\u001b[1;32m   2691\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2692\u001b[0m                 \u001b[0mfeed_input_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training_utils_v1.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    712\u001b[0m                 \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m    715\u001b[0m                         \u001b[0;34m\"Error when checking \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m                         \u001b[0;34m+\u001b[0m \u001b[0mexception_prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Error when checking input: expected conv2d_4_input to have 4 dimensions, but got array with shape (1, 1, 2)"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Cg6_M_1lv67_"},"execution_count":null,"outputs":[]}]}