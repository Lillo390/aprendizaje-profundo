{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"GU6Ab3QckvLF"},"source":["# **Ejemplo de uso del framework Stable Baselines 3 en Space Invaders**"]},{"cell_type":"markdown","metadata":{"id":"c50j4558k-7R"},"source":["Primero instalamos el framework"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BLumqs3_F-o7","executionInfo":{"status":"ok","timestamp":1681577894195,"user_tz":-120,"elapsed":13215,"user":{"displayName":"Carlos Blom-Dahl","userId":"13821063228198029433"}},"outputId":"cc8a8c33-86f2-4032-c50f-fc10b7ce8b2a"},"source":["# Esto hacÃ­a falta antes\n","#!pip install --upgrade --force-reinstall gym\n","\n","# La opcion oficial no funciona 5/4/2023\n","#!pip install stable_baselines3[extra]\n","\n","# Alternativa \n","!pip install git+https://github.com/carlosluis/stable-baselines3@fix_tests"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/carlosluis/stable-baselines3@fix_tests\n","  Cloning https://github.com/carlosluis/stable-baselines3 (to revision fix_tests) to /tmp/pip-req-build-8_y9ub8r\n","  Running command git clone --filter=blob:none --quiet https://github.com/carlosluis/stable-baselines3 /tmp/pip-req-build-8_y9ub8r\n","  Running command git checkout -b fix_tests --track origin/fix_tests\n","  Switched to a new branch 'fix_tests'\n","  Branch 'fix_tests' set up to track remote branch 'fix_tests' from 'origin'.\n","  Resolved https://github.com/carlosluis/stable-baselines3 to commit 6617e6e73cb3a70f3e88cea780ea12bed95c099e\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: gym==0.26.2 in /usr/local/lib/python3.9/dist-packages (from stable-baselines3==2.0.0a0) (0.26.2)\n","Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.9/dist-packages (from stable-baselines3==2.0.0a0) (2.0.0+cu118)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.9/dist-packages (from stable-baselines3==2.0.0a0) (2.2.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from stable-baselines3==2.0.0a0) (1.5.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from stable-baselines3==2.0.0a0) (3.7.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from stable-baselines3==2.0.0a0) (1.22.4)\n","Requirement already satisfied: importlib-metadata~=4.13 in /usr/local/lib/python3.9/dist-packages (from stable-baselines3==2.0.0a0) (4.13.0)\n","Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.9/dist-packages (from gym==0.26.2->stable-baselines3==2.0.0a0) (0.0.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata~=4.13->stable-baselines3==2.0.0a0) (3.15.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a0) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a0) (3.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a0) (3.11.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a0) (4.5.0)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a0) (2.0.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a0) (3.1.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.11->stable-baselines3==2.0.0a0) (16.0.1)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.11->stable-baselines3==2.0.0a0) (3.25.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->stable-baselines3==2.0.0a0) (1.0.7)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->stable-baselines3==2.0.0a0) (2.8.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->stable-baselines3==2.0.0a0) (1.4.4)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->stable-baselines3==2.0.0a0) (4.39.3)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->stable-baselines3==2.0.0a0) (3.0.9)\n","Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->stable-baselines3==2.0.0a0) (5.12.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->stable-baselines3==2.0.0a0) (23.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->stable-baselines3==2.0.0a0) (0.11.0)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->stable-baselines3==2.0.0a0) (8.4.0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->stable-baselines3==2.0.0a0) (2022.7.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3==2.0.0a0) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.11->stable-baselines3==2.0.0a0) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.11->stable-baselines3==2.0.0a0) (1.3.0)\n"]}]},{"cell_type":"markdown","metadata":{"id":"uw5T73jzlDEV"},"source":["descargamos los roms de atari"]},{"cell_type":"code","source":["!pip3 install gym[atari,accept-rom-license]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aWOjFYFKG_pj","executionInfo":{"status":"ok","timestamp":1681577903682,"user_tz":-120,"elapsed":9498,"user":{"displayName":"Carlos Blom-Dahl","userId":"13821063228198029433"}},"outputId":"58840cd8-fab9-4972-f459-f73da38efcd6"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gym[accept-rom-license,atari] in /usr/local/lib/python3.9/dist-packages (0.26.2)\n","Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.9/dist-packages (from gym[accept-rom-license,atari]) (0.0.8)\n","Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.9/dist-packages (from gym[accept-rom-license,atari]) (1.22.4)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from gym[accept-rom-license,atari]) (2.2.1)\n","Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.9/dist-packages (from gym[accept-rom-license,atari]) (4.13.0)\n","Requirement already satisfied: ale-py~=0.8.0 in /usr/local/lib/python3.9/dist-packages (from gym[accept-rom-license,atari]) (0.8.1)\n","Requirement already satisfied: autorom[accept-rom-license]~=0.4.2 in /usr/local/lib/python3.9/dist-packages (from gym[accept-rom-license,atari]) (0.4.2)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.9/dist-packages (from ale-py~=0.8.0->gym[accept-rom-license,atari]) (5.12.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from ale-py~=0.8.0->gym[accept-rom-license,atari]) (4.5.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (4.65.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (8.1.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.27.1)\n","Requirement already satisfied: AutoROM.accept-rom-license in /usr/local/lib/python3.9/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (0.6.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.8.0->gym[accept-rom-license,atari]) (3.15.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (1.26.15)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.0.12)\n"]}]},{"cell_type":"markdown","metadata":{"id":"gfhXieo9lJhv"},"source":["Importamos las librerias necesarias."]},{"cell_type":"code","metadata":{"id":"D117b4vnF2DD","executionInfo":{"status":"ok","timestamp":1681577909115,"user_tz":-120,"elapsed":827,"user":{"displayName":"Carlos Blom-Dahl","userId":"13821063228198029433"}}},"source":["import gym\n","#from gym.wrappers import Monitor"],"execution_count":4,"outputs":[]},{"cell_type":"code","source":["import base64\n","from pathlib import Path\n","from IPython import display as ipythondisplay\n","from stable_baselines3 import A2C\n","from stable_baselines3.common.env_util import make_vec_env\n","import os\n","\n","from stable_baselines3.common.evaluation import evaluate_policy"],"metadata":{"id":"vhEKOT7WoEkd","executionInfo":{"status":"ok","timestamp":1681577921296,"user_tz":-120,"elapsed":11013,"user":{"displayName":"Carlos Blom-Dahl","userId":"13821063228198029433"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yxdRrV_klMcT"},"source":["Cargamos el entorno"]},{"cell_type":"code","metadata":{"id":"Ob4NFuqGGm3q"},"source":["ENV_NAME = 'SpaceInvaders-v4'\n","env = gym.make(ENV_NAME)\n","height, width, channels = env.observation_space.shape\n","actions = env.action_space.n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8ouKE00JlRCn"},"source":["Preparamos el entorno para poder descargar los videos"]},{"cell_type":"code","metadata":{"id":"LlUA_pIIhNWj"},"source":["# experiment_dir = os.path.abspath(\"./experiments/{}\".format(env.spec.id))\n","# monitor_path = os.path.join(experiment_dir, \"monitor\")\n","\n","# if not os.path.exists(monitor_path):\n","#     os.makedirs(monitor_path)\n","# env = Monitor(env, directory=monitor_path, video_callable=lambda count: count % record_video_every == 0, resume=True)\n","# record_video_every =1\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"64eWZy8-lbud"},"source":["Cargamos el modelo precargado, le damos a entrenar y luego salvamos el entorno.\n","\n","Vamos a dejar todos los parametros por defecto, que en el caso del Advantage Actor Critic (A2C) usa:\n","- learning_rate = 0,0007 , \n","- n_steps = 5 , \n","- gamma = 0,99 ,\n","- gae_lambda = 1,0 , \n","- ent_coef = 0,0 , \n","- vf_coef = 0,5 , \n","- max_grad_norm = 0,5 , \n","- rms_prop_eps = 1e-05"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1-vNtcuDGzAa","executionInfo":{"status":"ok","timestamp":1681565752149,"user_tz":-120,"elapsed":129119,"user":{"displayName":"Carlos Blom-Dahl","userId":"13821063228198029433"}},"outputId":"1f6daecb-d5a0-4536-d67c-9ac0cff36e62"},"source":["model = A2C(\"MlpPolicy\", env, verbose=1) #Podemos elegir entre varias politicas, como MLPpolicy, CnnPolicy, MultiInputPolicy\n","model.learn(total_timesteps=5000)\n","model.save(\"a2c_SpaceInvaders\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using cpu device\n","Wrapping the env with a `Monitor` wrapper\n","Wrapping the env in a DummyVecEnv.\n","Wrapping the env in a VecTransposeImage.\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 36        |\n","|    iterations         | 100       |\n","|    time_elapsed       | 13        |\n","|    total_timesteps    | 500       |\n","| train/                |           |\n","|    entropy_loss       | -1.51     |\n","|    explained_variance | 0.0363    |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 99        |\n","|    policy_loss        | -6.86e-05 |\n","|    value_loss         | 1.52e-09  |\n","-------------------------------------\n","-------------------------------------\n","| rollout/              |           |\n","|    ep_len_mean        | 514       |\n","|    ep_rew_mean        | 50        |\n","| time/                 |           |\n","|    fps                | 35        |\n","|    iterations         | 200       |\n","|    time_elapsed       | 27        |\n","|    total_timesteps    | 1000      |\n","| train/                |           |\n","|    entropy_loss       | -1.45     |\n","|    explained_variance | -0.0299   |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 199       |\n","|    policy_loss        | -7.96e-06 |\n","|    value_loss         | 6.56e-11  |\n","-------------------------------------\n","-------------------------------------\n","| rollout/              |           |\n","|    ep_len_mean        | 506       |\n","|    ep_rew_mean        | 45        |\n","| time/                 |           |\n","|    fps                | 36        |\n","|    iterations         | 300       |\n","|    time_elapsed       | 41        |\n","|    total_timesteps    | 1500      |\n","| train/                |           |\n","|    entropy_loss       | -1.11     |\n","|    explained_variance | -0.00251  |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 299       |\n","|    policy_loss        | -0.000372 |\n","|    value_loss         | 3.6e-07   |\n","-------------------------------------\n","-------------------------------------\n","| rollout/              |           |\n","|    ep_len_mean        | 506       |\n","|    ep_rew_mean        | 45        |\n","| time/                 |           |\n","|    fps                | 36        |\n","|    iterations         | 400       |\n","|    time_elapsed       | 54        |\n","|    total_timesteps    | 2000      |\n","| train/                |           |\n","|    entropy_loss       | -1.19     |\n","|    explained_variance | -0.000944 |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 399       |\n","|    policy_loss        | -0.00679  |\n","|    value_loss         | 1.41e-05  |\n","-------------------------------------\n","------------------------------------\n","| rollout/              |          |\n","|    ep_len_mean        | 773      |\n","|    ep_rew_mean        | 140      |\n","| time/                 |          |\n","|    fps                | 37       |\n","|    iterations         | 500      |\n","|    time_elapsed       | 67       |\n","|    total_timesteps    | 2500     |\n","| train/                |          |\n","|    entropy_loss       | -0.665   |\n","|    explained_variance | 4.59e-05 |\n","|    learning_rate      | 0.0007   |\n","|    n_updates          | 499      |\n","|    policy_loss        | -0.00918 |\n","|    value_loss         | 7.66e-05 |\n","------------------------------------\n","-------------------------------------\n","| rollout/              |           |\n","|    ep_len_mean        | 773       |\n","|    ep_rew_mean        | 140       |\n","| time/                 |           |\n","|    fps                | 37        |\n","|    iterations         | 600       |\n","|    time_elapsed       | 80        |\n","|    total_timesteps    | 3000      |\n","| train/                |           |\n","|    entropy_loss       | -0.524    |\n","|    explained_variance | 0.00319   |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 599       |\n","|    policy_loss        | -0.000213 |\n","|    value_loss         | 3.8e-06   |\n","-------------------------------------\n","-------------------------------------\n","| rollout/              |           |\n","|    ep_len_mean        | 756       |\n","|    ep_rew_mean        | 118       |\n","| time/                 |           |\n","|    fps                | 38        |\n","|    iterations         | 700       |\n","|    time_elapsed       | 92        |\n","|    total_timesteps    | 3500      |\n","| train/                |           |\n","|    entropy_loss       | -0.647    |\n","|    explained_variance | 0.407     |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 699       |\n","|    policy_loss        | -1.88e-06 |\n","|    value_loss         | 4.82e-12  |\n","-------------------------------------\n","-------------------------------------\n","| rollout/              |           |\n","|    ep_len_mean        | 725       |\n","|    ep_rew_mean        | 95        |\n","| time/                 |           |\n","|    fps                | 38        |\n","|    iterations         | 800       |\n","|    time_elapsed       | 104       |\n","|    total_timesteps    | 4000      |\n","| train/                |           |\n","|    entropy_loss       | -0.607    |\n","|    explained_variance | -1.57e-05 |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 799       |\n","|    policy_loss        | -0.00439  |\n","|    value_loss         | 5.78e-05  |\n","-------------------------------------\n","-------------------------------------\n","| rollout/              |           |\n","|    ep_len_mean        | 720       |\n","|    ep_rew_mean        | 109       |\n","| time/                 |           |\n","|    fps                | 38        |\n","|    iterations         | 900       |\n","|    time_elapsed       | 116       |\n","|    total_timesteps    | 4500      |\n","| train/                |           |\n","|    entropy_loss       | -0.345    |\n","|    explained_variance | 0.000179  |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 899       |\n","|    policy_loss        | -0.000671 |\n","|    value_loss         | 9.82e-05  |\n","-------------------------------------\n","------------------------------------\n","| rollout/              |          |\n","|    ep_len_mean        | 706      |\n","|    ep_rew_mean        | 98.6     |\n","| time/                 |          |\n","|    fps                | 38       |\n","|    iterations         | 1000     |\n","|    time_elapsed       | 128      |\n","|    total_timesteps    | 5000     |\n","| train/                |          |\n","|    entropy_loss       | -0.33    |\n","|    explained_variance | 7.68e-05 |\n","|    learning_rate      | 0.0007   |\n","|    n_updates          | 999      |\n","|    policy_loss        | 1.63e-05 |\n","|    value_loss         | 6.56e-08 |\n","------------------------------------\n"]}]},{"cell_type":"code","metadata":{"id":"AeIgpBKZpPcf"},"source":["recompensa_media, desviacion = evaluate_policy(model, model.get_env(), deterministic=True, n_eval_episodes=20)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"recompensa_media:{recompensa_media:.2f} +/- {desviacion:.2f}\")"],"metadata":{"id":"tds9ubHuDN4C","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681566603112,"user_tz":-120,"elapsed":193,"user":{"displayName":"Carlos Blom-Dahl","userId":"13821063228198029433"}},"outputId":"1414fa72-ef0b-44f0-99bd-feca39966f70"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["recompensa_media:0.00 +/- 0.00\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"4ycp3xvPUd1U"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["--------------------\n","# ImplementaciÃ³n de DQL\n"],"metadata":{"id":"ypnMbOL9ryVo"}},{"cell_type":"markdown","source":["Para implementar _Deep Q-Network_, necesitaremos emplear la biblioteca _TensorFlow_."],"metadata":{"id":"6Fs8pQ9btZAn"}},{"cell_type":"code","source":["!pip3 install tensorflow==2.10.1\n","!pip install keras-rl2\n","!pip install h5py\n","!pip install Pillow"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T4hv3LKgtNpa","executionInfo":{"status":"ok","timestamp":1681577843221,"user_tz":-120,"elapsed":27967,"user":{"displayName":"Carlos Blom-Dahl","userId":"13821063228198029433"}},"outputId":"18b011aa-fb9c-43b8-b53f-3b323e1ae0c3"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tensorflow==2.10.1 in /usr/local/lib/python3.9/dist-packages (2.10.1)\n","Requirement already satisfied: keras<2.11,>=2.10.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.1) (2.10.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.1) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.1) (3.8.0)\n","Requirement already satisfied: tensorboard<2.11,>=2.10 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.1) (2.10.1)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.1) (1.53.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.1) (1.1.2)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.1) (3.19.6)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.1) (1.22.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.1) (23.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.1) (2.2.0)\n","Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.1) (2.10.0)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.1) (0.4.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.1) (0.32.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.1) (1.14.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.1) (3.3.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.1) (1.4.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.1) (16.0.0)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.1) (23.3.3)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.1) (1.6.3)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.1) (4.5.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.1) (67.6.1)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.1) (1.16.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow==2.10.1) (0.40.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.1) (3.4.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.1) (2.27.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.1) (0.6.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.1) (2.17.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.1) (2.2.3)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.1) (1.8.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.1) (0.4.6)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (0.2.8)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (5.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (4.13.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (3.4)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (2022.12.7)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (2.1.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (3.15.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (3.2.2)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: keras-rl2 in /usr/local/lib/python3.9/dist-packages (1.0.5)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.9/dist-packages (from keras-rl2) (2.10.1)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (23.3.3)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (16.0.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (23.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (0.32.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (3.3.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (4.5.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (2.2.0)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (1.22.4)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (1.1.2)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (0.4.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (1.16.0)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (3.19.6)\n","Requirement already satisfied: tensorboard<2.11,>=2.10 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (2.10.1)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (1.53.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (1.6.3)\n","Requirement already satisfied: keras<2.11,>=2.10.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (2.10.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (67.6.1)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (3.8.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (0.2.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (1.4.0)\n","Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (2.10.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow->keras-rl2) (0.40.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (2.27.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (0.4.6)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (3.4.3)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (0.6.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (2.17.2)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (1.8.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (2.2.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (0.2.8)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (5.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (4.13.0)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (3.4)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (2.1.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (3.15.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (3.2.2)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: h5py in /usr/local/lib/python3.9/dist-packages (3.8.0)\n","Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.9/dist-packages (from h5py) (1.22.4)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.9/dist-packages (8.4.0)\n"]}]},{"cell_type":"code","source":["print(\"The size of frame is: \", env.observation_space.shape)\n","print(\"No. of Actions: \", env.action_space.n)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R0DygVZa30g7","executionInfo":{"status":"ok","timestamp":1681579670338,"user_tz":-120,"elapsed":243,"user":{"displayName":"Carlos Blom-Dahl","userId":"13821063228198029433"}},"outputId":"a15366ff-2f6d-4d47-aa08-35a8e5e9514f"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["The size of frame is:  (210, 160, 3)\n","No. of Actions:  6\n"]}]},{"cell_type":"markdown","source":["## Preprocesamiento de los datos\n","\n","El preprocesado es un paso importante, ya que buscamos reducir la complejidad de nuestros estados para reducir el tiempo de computaciÃ³n necesari durante el entrenamiento.\n","\n","Los pasos que vamos a seguir son:\n","\n","* Pasar cada uno de los frames a escala de grises (porque el color no aÃ±ade informaciÃ³n relevante).\n","\n","* Recortar la pantalla (en nuestro caso, eliminamos la parte de debajo del jugador porque no aporta informaciÃ³n Ãºtil).\n","\n","* Normalizar los valores de los pÃ­xeles.\n","\n","* Redimensionar el frame procesado."],"metadata":{"id":"9R0oqdnL9vO4"}},{"cell_type":"code","source":["!pip install -U scikit-image"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"adKdQt4s_Lze","executionInfo":{"status":"ok","timestamp":1681580176384,"user_tz":-120,"elapsed":24336,"user":{"displayName":"Carlos Blom-Dahl","userId":"13821063228198029433"}},"outputId":"81d077b2-cbc6-4fbd-81a6-388d4a3e067b"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.9/dist-packages (0.19.3)\n","Collecting scikit-image\n","  Downloading scikit_image-0.20.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.2 MB)\n","\u001b[2K     \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pillow>=9.0.1\n","  Downloading Pillow-9.5.0-cp39-cp39-manylinux_2_28_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.9/dist-packages (from scikit-image) (3.1)\n","Requirement already satisfied: numpy>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image) (1.22.4)\n","Collecting scipy<1.9.2,>=1.8\n","  Downloading scipy-1.9.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)\n","\u001b[2K     \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m43.9/43.9 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image) (2.25.1)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image) (1.4.1)\n","Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image) (0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from scikit-image) (23.0)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.9/dist-packages (from scikit-image) (2023.3.21)\n","Installing collected packages: scipy, pillow, scikit-image\n","  Attempting uninstall: scipy\n","    Found existing installation: scipy 1.10.1\n","    Uninstalling scipy-1.10.1:\n","      Successfully uninstalled scipy-1.10.1\n","  Attempting uninstall: pillow\n","    Found existing installation: Pillow 8.4.0\n","    Uninstalling Pillow-8.4.0:\n","      Successfully uninstalled Pillow-8.4.0\n","  Attempting uninstall: scikit-image\n","    Found existing installation: scikit-image 0.19.3\n","    Uninstalling scikit-image-0.19.3:\n","      Successfully uninstalled scikit-image-0.19.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","dopamine-rl 4.0.6 requires gym<=0.25.2, but you have gym 0.26.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed pillow-9.5.0 scikit-image-0.20.0 scipy-1.9.1\n"]}]},{"cell_type":"code","source":["from skimage import transform\n","from skimage import io\n","from skimage.color import rgb2gray\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","\n","from collections import deque\n","\n","import random\n","\n","import warnings # This ignore all the warning messages that are normally printed during the training because of skiimage\n","warnings.filterwarnings('ignore') "],"metadata":{"id":"ax_7WxOC-twj","executionInfo":{"status":"ok","timestamp":1681581080099,"user_tz":-120,"elapsed":213,"user":{"displayName":"Carlos Blom-Dahl","userId":"13821063228198029433"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","    preprocess_frame:\n","    Take a frame.\n","    Grayscale it\n","    Resize it.\n","        __________________\n","        |                 |\n","        |                 |\n","        |                 |\n","        |                 |\n","        |_________________|\n","        \n","        to\n","        _____________\n","        |            |\n","        |            |\n","        |            |\n","        |____________|\n","    Normalize it.\n","    \n","    return preprocessed_frame\n","    \n","    \"\"\"\n","def preprocess_frame(frame):\n","    # Greyscale frame \n","    gray = rgb2gray(frame)\n","    \n","    # Crop the screen (remove the part below the player)\n","    # [Up: Down, Left: right]\n","    cropped_frame = gray[8:-12,4:-12]\n","    \n","    # Normalize Pixel Values\n","    normalized_frame = cropped_frame/255.0\n","    \n","    # Resize\n","    preprocessed_frame = transform.resize(normalized_frame, [110,84])\n","    \n","    return preprocessed_frame # 110x84x1 frame"],"metadata":{"id":"Vwn6BUcM-iXB","executionInfo":{"status":"ok","timestamp":1681580305711,"user_tz":-120,"elapsed":216,"user":{"displayName":"Carlos Blom-Dahl","userId":"13821063228198029433"}}},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":["Vamos a apilar (_stack_) los frames.\n","Apilar los frames es realmente importante porque nos ayuda a darle sentido de movimiento a nuestra Red Neuronal.\n","\n","PERO, no apilamos cada frame, saltamos 4 frames en cada paso de tiempo. Esto significa que solo se considera cada cuatro frames. Luego, usamos este frame para formar el frame apilado.\n","\n","El mÃ©todo de salto de frames ya estÃ¡ implementado en la biblioteca.\n","\n","* Primero preprocesamos el frame.\n","\n","* Luego lo aÃ±adimos a la cola (deque) que automÃ¡ticamente elimina el frame mÃ¡s antiguo.\n","\n","* Finalmente construimos el estado apilado.\n","\n","AsÃ­ es como funciona el apilado:\n","\n","* Para el primer frame, alimentamos con 4 frames.\n","* En cada paso de tiempo, aÃ±adimos el nuevo frame a la cola y luego los apilamos para formar un nuevo frame apilado.\n","\n","Y asÃ­ sucesivamente.\n","\n","**Si hemos terminado, creamos una nueva pila con 4 frames nuevos (porque estamos en un nuevo episodio).**"],"metadata":{"id":"jzgJ1t1eAORa"}},{"cell_type":"code","source":["stack_size = 4 # We stack 4 frames\n","\n","# Initialize deque with zero-images one array for each image\n","stacked_frames  =  deque([np.zeros((110,84), dtype=np.int) for i in range(stack_size)], maxlen=4)\n","\n","def stack_frames(stacked_frames, state, is_new_episode):\n","    # Preprocess frame\n","    frame = preprocess_frame(state)\n","    \n","    if is_new_episode:\n","        # Clear our stacked_frames\n","        stacked_frames = deque([np.zeros((110,84), dtype=np.int) for i in range(stack_size)], maxlen=4)\n","        \n","        # Because we're in a new episode, copy the same frame 4x\n","        stacked_frames.append(frame)\n","        stacked_frames.append(frame)\n","        stacked_frames.append(frame)\n","        stacked_frames.append(frame)\n","        \n","        # Stack the frames\n","        stacked_state = np.stack(stacked_frames, axis=2)\n","        \n","    else:\n","        # Append frame to deque, automatically removes the oldest frame\n","        stacked_frames.append(frame)\n","\n","        # Build the stacked state (first dimension specifies different frames)\n","        stacked_state = np.stack(stacked_frames, axis=2) \n","    \n","    return stacked_state, stacked_frames"],"metadata":{"id":"jFppDlirBUtU","executionInfo":{"status":"ok","timestamp":1681580767009,"user_tz":-120,"elapsed":222,"user":{"displayName":"Carlos Blom-Dahl","userId":"13821063228198029433"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["### MODEL HYPERPARAMETERS\n","state_size = [110, 84, 4]      # Our input is a stack of 4 frames hence 110x84x4 (Width, height, channels) \n","action_size = env.action_space.n # 8 possible actions\n","learning_rate =  0.00025      # Alpha (aka learning rate)\n","\n","### TRAINING HYPERPARAMETERS\n","total_episodes = 50            # Total episodes for training\n","max_steps = 50000              # Max possible steps in an episode\n","batch_size = 64                # Batch size\n","\n","# Exploration parameters for epsilon greedy strategy\n","explore_start = 1.0            # exploration probability at start\n","explore_stop = 0.01            # minimum exploration probability \n","decay_rate = 0.00001           # exponential decay rate for exploration prob\n","\n","# Q learning hyperparameters\n","gamma = 0.9                    # Discounting rate\n","\n","### MEMORY HYPERPARAMETERS\n","pretrain_length = batch_size   # Number of experiences stored in the Memory when initialized for the first time\n","memory_size = 1000000          # Number of experiences the Memory can keep\n","\n","### PREPROCESSING HYPERPARAMETERS\n","stack_size = 4                 # Number of frames stacked\n","\n","### MODIFY THIS TO FALSE IF YOU JUST WANT TO SEE THE TRAINED AGENT\n","training = False\n","\n","## TURN THIS TO TRUE IF YOU WANT TO RENDER THE ENVIRONMENT\n","episode_render = False"],"metadata":{"id":"FQ4FiBEPBuCI","executionInfo":{"status":"ok","timestamp":1681580813057,"user_tz":-120,"elapsed":250,"user":{"displayName":"Carlos Blom-Dahl","userId":"13821063228198029433"}}},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":["Ahora vamos a crear el modelo DQL:\n","- Tomamos una pila de 4 fotogramas como entrada.\n","- Pasa a travÃ©s de 3 convnets.\n","- Luego se aplana.\n","- Finalmente pasa a travÃ©s de 2 capas completamente conectadas (_dense_).\n","- Devuelve un valor Q para cada acciÃ³n."],"metadata":{"id":"120-qcAxB9gG"}},{"cell_type":"code","source":["import tensorflow as tf\n","\n","class DQNetwork:\n","    def __init__(self, state_size, action_size, learning_rate, name='DQNetwork'):\n","        self.state_size = state_size\n","        self.action_size = action_size\n","        self.learning_rate = learning_rate\n","        \n","        with tf.name_scope(name):\n","            # We create the placeholders\n","            # *state_size means that we take each elements of state_size in tuple hence is like if we wrote\n","            # [None, 84, 84, 4]\n","            self.inputs_ = tf.placeholder(tf.float32, [None, *state_size], name=\"inputs\")\n","            self.actions_ = tf.placeholder(tf.float32, [None, self.action_size], name=\"actions_\")\n","            \n","            # Remember that target_Q is the R(s,a) + ymax Qhat(s', a')\n","            self.target_Q = tf.placeholder(tf.float32, [None], name=\"target\")\n","            \n","            \"\"\"\n","            First convnet:\n","            CNN\n","            ELU\n","            \"\"\"\n","            # Input is 110x84x4 \n","            self.conv1 = tf.keras.layers.Conv2D(filters=32,\n","                                  kernel_size=[8, 8],\n","                                  strides=[4, 4],\n","                                  padding=\"VALID\",\n","                                  kernel_initializer=tf.keras.initializers.GlorotUniform(),\n","                                  name=\"conv1\")(self.inputs_)\n","\n","            \n","            self.conv1_out = tf.nn.elu(self.conv1, name=\"conv1_out\")\n","            \n","            \"\"\"\n","            Second convnet:\n","            CNN\n","            ELU\n","            \"\"\"\n","            self.conv2 = tf.keras.layers.Conv2D(filters = 64,\n","                                 kernel_size = [4,4],\n","                                 strides = [2,2],\n","                                 padding = \"VALID\",\n","                                kernel_initializer=tf.keras.initializers.GlorotUniform(),\n","                                 name = \"conv2\")(self.conv1_out)\n","\n","            self.conv2_out = tf.nn.elu(self.conv2, name=\"conv2_out\")            \n","            \n","            \"\"\"\n","            Third convnet:\n","            CNN\n","            ELU\n","            \"\"\"\n","            self.conv3 = tf.keras.layers.Conv2D(filters = 64,\n","                                 kernel_size = [3,3],\n","                                 strides = [2,2],\n","                                 padding = \"VALID\",\n","                                kernel_initializer=tf.keras.initializers.GlorotUniform(),\n","                                 name = \"conv3\")(self.conv2_out)\n","\n","            self.conv3_out = tf.nn.elu(self.conv3, name=\"conv3_out\")\n","            \n","            self.flatten = tf.keras.layers.Flatten()(self.conv3_out)\n","            \n","            self.fc1 = tf.keras.layers.Dense(units = 512,\n","                                  activation = tf.nn.elu,\n","                                  kernel_initializer=tf.keras.initializers.GlorotUniform(),\n","                                  name=\"fc1\")(self.flatten)\n","            \n","            self.output = tf.keras.layers.Dense(units = self.action_size, \n","                                           activation=None,\n","                                           kernel_initializer=tf.keras.initializers.GlorotUniform())(self.fc1)\n","            \n","\n","  \n","            # Q is our predicted Q value.\n","            self.Q = tf.reduce_sum(tf.multiply(self.output, self.actions_))\n","            \n","            # The loss is the difference between our predicted Q_values and the Q_target\n","            # Sum(Qtarget - Q)^2\n","            self.loss = tf.reduce_mean(tf.square(self.target_Q - self.Q))\n","            \n","            self.optimizer = tf.keras.optimizers.Adam(self.learning_rate).minimize(self.loss)\n","\n"],"metadata":{"id":"bZru-0AQCUet","executionInfo":{"status":"ok","timestamp":1681582281489,"user_tz":-120,"elapsed":228,"user":{"displayName":"Carlos Blom-Dahl","userId":"13821063228198029433"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["# Instantiate the DQNetwork\n","DQNetwork = DQNetwork(state_size, action_size, learning_rate)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":305},"id":"3zyRFjE4CdV4","executionInfo":{"status":"error","timestamp":1681582284510,"user_tz":-120,"elapsed":267,"user":{"displayName":"Carlos Blom-Dahl","userId":"13821063228198029433"}},"outputId":"604a7e51-3029-46d9-8cdd-76076723e9a4"},"execution_count":48,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-48-8ed4bb5aa52a>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Instantiate the DQNetwork\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mDQNetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDQNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-47-d80b36bfdc82>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, state_size, action_size, learning_rate, name)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;31m# *state_size means that we take each elements of state_size in tuple hence is like if we wrote\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;31m# [None, 84, 84, 4]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"inputs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"actions_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'placeholder'"]}]},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, Flatten, Dense\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.activations import relu, linear\n","from rl.agents.dqn import DQNAgent\n","from rl.policy import BoltzmannQPolicy\n","from rl.memory import SequentialMemory\n","import gym\n","import numpy as np\n","\n","# Obtener el entorno y extraer el nÃºmero de acciones\n","ENV_NAME = 'SpaceInvaders-v4'\n","env = gym.make(ENV_NAME)\n","np.random.seed(123)\n","env.seed(123)\n","nb_actions = env.action_space.n\n","\n","# Construir el modelo con capas convolucionales\n","model = Sequential()\n","model.add(Conv2D(16, (3, 3), activation=relu, input_shape= env.observation_space.shape))\n","model.add(Conv2D(32, (3, 3), activation=relu))\n","model.add(Flatten())\n","model.add(Dense(nb_actions, activation=linear))\n","print(model.summary())\n","\n","# Configurar y compilar el agente\n","memory = SequentialMemory(limit=5000, window_length=1)\n","policy = BoltzmannQPolicy()\n","dqn = DQNAgent(model=model, nb_actions=nb_actions, memory=memory, nb_steps_warmup=10,\n","               target_model_update=1e-2, policy=policy)\n","dqn.compile(Adam(lr=1e-3), metrics=['mae'])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t2TEQJCMr_Ey","executionInfo":{"status":"ok","timestamp":1681578334699,"user_tz":-120,"elapsed":1497,"user":{"displayName":"Carlos Blom-Dahl","userId":"13821063228198029433"}},"outputId":"9b46d424-ee98-47a5-8744-be7c674d4cd1"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_4 (Conv2D)           (None, 208, 158, 16)      448       \n","                                                                 \n"," conv2d_5 (Conv2D)           (None, 206, 156, 32)      4640      \n","                                                                 \n"," flatten_2 (Flatten)         (None, 1028352)           0         \n","                                                                 \n"," dense_2 (Dense)             (None, 6)                 6170118   \n","                                                                 \n","=================================================================\n","Total params: 6,175,206\n","Trainable params: 6,175,206\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"]}]},{"cell_type":"code","source":["print(env.observation_space.shape)\n","print(type(env))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Poj0Kz7fv7E3","executionInfo":{"status":"ok","timestamp":1681576892161,"user_tz":-120,"elapsed":3,"user":{"displayName":"Carlos Blom-Dahl","userId":"13821063228198029433"}},"outputId":"c80d2510-6977-4662-8567-babdd9064133"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["(210, 160, 3)\n","<class 'gym.wrappers.order_enforcing.OrderEnforcing'>\n"]}]},{"cell_type":"code","source":["# Modificar la entrada para tener 4 dimensiones\n","#obs = np.expand_dims(env.reset(), axis=0)\n","dqn.fit(env, nb_steps=5000, visualize=False, verbose=2, nb_max_episode_steps=10000)\n","\n","# After training is done, we save the final weights.\n","dqn.save_weights('dqn_{}_weights.h5f'.format(ENV_NAME), overwrite=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":398},"id":"JtAl-f5pxI-u","executionInfo":{"status":"error","timestamp":1681578341879,"user_tz":-120,"elapsed":298,"user":{"displayName":"Carlos Blom-Dahl","userId":"13821063228198029433"}},"outputId":"f677f43c-38a7-42f1-baaa-ac7560171601"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Training for 5000 steps ...\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-cb635b26ce70>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Modificar la entrada para tener 4 dimensiones\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#obs = np.expand_dims(env.reset(), axis=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_max_episode_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# After training is done, we save the final weights.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/rl/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, env, nb_steps, action_repetition, callbacks, verbose, visualize, nb_max_start_steps, start_step_policy, log_interval, nb_max_episode_steps)\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;31m# This is were all of the work happens. We first perceive and compute the action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0;31m# (forward step) and then use the reward to improve (backward step).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m                 \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/rl/agents/dqn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, observation)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;31m# Select an action.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_recent_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mq_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_q_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mq_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/rl/agents/dqn.py\u001b[0m in \u001b[0;36mcompute_q_values\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_q_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mq_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_batch_q_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mq_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_actions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mq_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/rl/agents/dqn.py\u001b[0m in \u001b[0;36mcompute_batch_q_values\u001b[0;34m(self, state_batch)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_batch_q_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_state_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mq_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mq_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mq_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mpredict_on_batch\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1302\u001b[0m             )\n\u001b[1;32m   1303\u001b[0m         \u001b[0;31m# Validate and standardize user data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         inputs, _, _ = self._standardize_user_data(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_tensors_from_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2649\u001b[0;31m         return self._standardize_tensors(\n\u001b[0m\u001b[1;32m   2650\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2651\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py\u001b[0m in \u001b[0;36m_standardize_tensors\u001b[0;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001b[0m\n\u001b[1;32m   2688\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2689\u001b[0m             \u001b[0;31m# TODO(fchollet): run static checks with dataset output shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2690\u001b[0;31m             x = training_utils_v1.standardize_input_data(\n\u001b[0m\u001b[1;32m   2691\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2692\u001b[0m                 \u001b[0mfeed_input_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training_utils_v1.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    712\u001b[0m                 \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m    715\u001b[0m                         \u001b[0;34m\"Error when checking \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m                         \u001b[0;34m+\u001b[0m \u001b[0mexception_prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Error when checking input: expected conv2d_4_input to have 4 dimensions, but got array with shape (1, 1, 2)"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Cg6_M_1lv67_"},"execution_count":null,"outputs":[]}]}